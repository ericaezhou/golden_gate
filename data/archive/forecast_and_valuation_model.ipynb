{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q3 Risk Forecast Workstream \u2014 Alice Chen (Transition Package)\n",
        "\n",
        "This notebook produces the quarterly portfolio risk forecast used in the board memo.\n",
        "\n",
        "Inputs:\n",
        "- SQLite DB: `data/portfolio_risk.db`\n",
        "- Policy reference: `docs/risk_policy_v3_2.docx`\n",
        "- Historical run log: `analysis/alice_past_runs_and_sensitivity.xlsx`\n",
        "\n",
        "Outputs:\n",
        "- `analysis/current_run_output.csv`\n",
        "\n",
        "> **Note:** This notebook includes legacy shortcuts that may need alignment with policy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "DB_PATH = Path('data') / 'portfolio_risk.db'\n",
        "AS_OF_QUARTER = '2026Q1'\n",
        "\n",
        "# --- Legacy parameters (may be inconsistent with policy) ---\n",
        "FORECAST_WINDOW_QUARTERS = 4   # <-- legacy shortcut; policy may require 12\n",
        "STRESS_PD_MULTIPLIER = 1.10    # <-- legacy; policy may require 1.15\n",
        "DISCOUNT_RATE = 0.105          # <-- legacy; policy may approve 0.085\n",
        "\n",
        "conn = sqlite3.connect(DB_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy = pd.read_sql_query(\"SELECT * FROM policy_snapshot WHERE as_of_quarter = ?\", conn, params=[AS_OF_QUARTER])\n",
        "macro = pd.read_sql_query(\"SELECT * FROM macro_quarterly WHERE quarter = ?\", conn, params=[AS_OF_QUARTER])\n",
        "defaults = pd.read_sql_query(\"SELECT * FROM historical_defaults ORDER BY quarter\", conn)\n",
        "capital = pd.read_sql_query(\"SELECT * FROM capital_position ORDER BY quarter\", conn)\n",
        "cohorts = pd.read_sql_query(\"SELECT * FROM loan_cohorts\", conn)\n",
        "\n",
        "policy, macro.head(), defaults.tail(3), capital.tail(1), cohorts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 \u2014 Forecast base default rate\n",
        "\n",
        "We compute a rolling average default rate. (Legacy: 4-quarter window)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "window = FORECAST_WINDOW_QUARTERS\n",
        "avg_default = defaults['default_rate'].tail(window).mean()\n",
        "avg_default\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 \u2014 Apply macro overlay (if GDP trigger)\n",
        "\n",
        "Policy may require a multiplier when GDP growth is below a threshold.\n",
        "\n",
        "Legacy behavior in this notebook: **does not** apply overlay automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gdp = float(macro.loc[0, 'gdp_growth'])\n",
        "gdp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_pd_12m = avg_default  # simplification: treat quarterly avg as annualized proxy\n",
        "\n",
        "# NOTE: Macro overlay intentionally not applied here (knowledge gap)\n",
        "pd_macro_adjusted = base_pd_12m\n",
        "pd_macro_adjusted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 \u2014 Stress case and capital impact\n",
        "\n",
        "We apply a stress multiplier to PD and compute a simplified CET1 impact.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd_stress = pd_macro_adjusted * STRESS_PD_MULTIPLIER\n",
        "\n",
        "latest_cap = capital.tail(1).iloc[0]\n",
        "cet1_ratio_start = float(latest_cap['cet1_ratio'])\n",
        "cet1_capital = float(latest_cap['cet1_capital'])\n",
        "rwa = float(latest_cap['rwa'])\n",
        "\n",
        "# Simplified loss = sum(EAD * LGD * PD)\n",
        "loss_base = (cohorts['exposure_ead'] * cohorts['lgd']).sum() * pd_macro_adjusted\n",
        "loss_stress = (cohorts['exposure_ead'] * cohorts['lgd']).sum() * pd_stress\n",
        "\n",
        "cet1_capital_base = cet1_capital - loss_base\n",
        "cet1_capital_stress = cet1_capital - loss_stress\n",
        "\n",
        "cet1_ratio_base = cet1_capital_base / rwa\n",
        "cet1_ratio_stress = cet1_capital_stress / rwa\n",
        "\n",
        "cet1_ratio_start, cet1_ratio_base, cet1_ratio_stress\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 \u2014 Risk-adjusted NPV (toy valuation)\n",
        "\n",
        "We compute a simple risk-adjusted NPV of the portfolio cashflows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annual_cashflow = 1.15e9  # placeholder\n",
        "years = 5\n",
        "discount_factors = np.array([(1+DISCOUNT_RATE)**t for t in range(1, years+1)])\n",
        "\n",
        "# Risk adjustment: reduce cashflow by expected loss proportion\n",
        "expected_loss_prop = pd_macro_adjusted * 0.7  # heuristic\n",
        "adj_cashflow = annual_cashflow * (1 - expected_loss_prop)\n",
        "npv = (adj_cashflow / discount_factors).sum()\n",
        "npv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5 \u2014 Output report row\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = {\n",
        "    'as_of_quarter': AS_OF_QUARTER,\n",
        "    'forecast_window_quarters_used': FORECAST_WINDOW_QUARTERS,\n",
        "    'gdp_growth': gdp,\n",
        "    'pd_base_12m': float(pd_macro_adjusted),\n",
        "    'pd_stress_12m': float(pd_stress),\n",
        "    'cet1_ratio_start': float(cet1_ratio_start),\n",
        "    'cet1_ratio_base': float(cet1_ratio_base),\n",
        "    'cet1_ratio_stress': float(cet1_ratio_stress),\n",
        "    'discount_rate_used': float(DISCOUNT_RATE),\n",
        "    'risk_adjusted_npv': float(npv),\n",
        "}\n",
        "\n",
        "df_out = pd.DataFrame([out])\n",
        "df_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_path = Path('analysis') / 'current_run_output.csv'\n",
        "df_out.to_csv(out_path, index=False)\n",
        "print('Wrote', out_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}